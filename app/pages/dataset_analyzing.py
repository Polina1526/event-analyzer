import json
import time
from io import BytesIO

import constants
import data_processing
import pandas as pd
import pydantic
import streamlit as st
import utils
from catboost import CatBoostClassifier
from sklearn.preprocessing import LabelEncoder


st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö", page_icon="üîé")


def _prepare_for_display_model_pivot_table(df: pd.DataFrame) -> pd.DataFrame:
    df = df[
        [
            "data_file_name",
            "target_event_name",
            "learning_metrics",
            "learning_time",
            "feature_extraction_time",
            "settings",
        ]
    ]
    df = df.reset_index()

    learning_metrics_df: pd.DataFrame = pd.json_normalize(df["learning_metrics"])
    col_position: int = df.columns.get_loc("learning_metrics")
    df = df.drop(columns=["learning_metrics"])
    df = pd.concat([df.iloc[:, :col_position], learning_metrics_df, df.iloc[:, col_position:]], axis=1)

    df = df.rename(
        columns={
            "index": "–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏",
            "data_file_name": "–ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏",
            "target_event_name": "–ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–æ–±—ã—Ç–∏—è",
            "learning_metrics": "–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏",
            "learning_time": "–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏",
            "feature_extraction_time": "–í—Ä–µ–º—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏—á–µ–π",
            "settings": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏",
        }
    )
    return df


class SidebarSettings(pydantic.BaseModel):
    feature_extruction_chunksize: int


def create_sidebar(threadid_count: int) -> SidebarSettings:
    feature_extruction_chunksize: int = st.sidebar.number_input(
        label="–ö–æ–ª-–≤–æ —Ü–µ–ø–æ—á–µ–∫ –≤ –æ–¥–Ω–æ–º —á–∞–Ω–∫–µ –ø—Ä–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–µ",
        min_value=1,
        max_value=threadid_count,
        value=min(constants.DEFAULT_CHUNKSIZE, threadid_count),
        step=1,
    )
    return SidebarSettings(feature_extruction_chunksize=feature_extruction_chunksize)


def prepare_for_excel_download(df: pd.DataFrame) -> bytes:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False)
    return output.getvalue()


def transform_y(
    y_df: pd.DataFrame, threadid_col_name: str, target_event_name: str, event_chain_id_col_le: LabelEncoder
) -> pd.DataFrame:
    y_df = y_df.reset_index(f"{constants.EVENT_CHAIN_ID_CON_NAME}_encoded")
    y_df[constants.EVENT_CHAIN_ID_CON_NAME] = event_chain_id_col_le.inverse_transform(
        y_df[f"{constants.EVENT_CHAIN_ID_CON_NAME}_encoded"]
    )
    y_df[threadid_col_name] = y_df[constants.EVENT_CHAIN_ID_CON_NAME].str.split("_").str[0]
    y_df = y_df.drop(columns=["y", f"{constants.EVENT_CHAIN_ID_CON_NAME}_encoded", constants.EVENT_CHAIN_ID_CON_NAME])
    y_df = y_df[[threadid_col_name, f"{target_event_name}_occurrence_prob"]]
    return y_df


def dataset_analyzing_page() -> None:
    st.title("–ê–Ω–∞–ª–∏–∑ —Å–æ–±—ã—Ç–∏–π —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")

    with open(constants.MODEL_PIVOT_TABLE_PATH, "r") as file:
        model_pivot_table_dict: dict[str, dict] = json.load(file)

    model_pivot_table_df: pd.DataFrame = pd.DataFrame.from_dict(model_pivot_table_dict, orient="index")

    st.header("–î–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –º–æ–¥–µ–ª–∏")
    st.dataframe(
        _prepare_for_display_model_pivot_table(model_pivot_table_df),
        column_config={"settings": st.column_config.JsonColumn("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏", width="large")},
        hide_index=True,
    )

    _model_name: list[str] = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö", model_pivot_table_df.index, max_selections=1
    )
    if not _model_name:
        st.stop()
    model_name: str = _model_name[0]
    model: CatBoostClassifier = CatBoostClassifier().load_model(constants.MODEL_SAVING_PATH.format(model_name))
    main_features: list[str] = model_pivot_table_df.loc[
        (model_pivot_table_df.index == model_name), "main_features"
    ].iloc[0]
    target_event_name: str = model_pivot_table_df.loc[
        (model_pivot_table_df.index == model_name), "target_event_name"
    ].iloc[0]
    window_days: int = model_pivot_table_df.loc[(model_pivot_table_df.index == model_name), "window_days"].iloc[0]

    raw_data: pd.DataFrame
    raw_data, _ = utils.load_train_data(label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    threadid_col_name: str
    raw_data, threadid_col_name = data_processing.column_standardization(raw_data, return_threadid_col_name=True)

    # TODO: –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–ª–∞—Ç–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    raw_data = raw_data[raw_data[constants.EVENT_TYPE_COL_NAME] != target_event_name]
    # TODO: –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–ª–∞—Ç–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

    processed_data: pd.DataFrame
    y_to_id_mapping: pd.DataFrame
    event_chain_id_col_le: LabelEncoder
    processed_data, y_to_id_mapping, event_chain_id_col_le = data_processing.preprocess_data(
        df=raw_data, target_event=target_event_name, time_window=f"{window_days}D"
    )

    sidebar_settings: SidebarSettings = create_sidebar(
        threadid_count=processed_data[constants.THREADID_COL_NAME].nunique()
    )

    with st.form("analyzing_start_form"):
        result_file_name: str = st.text_input(label="–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞")
        form_send: bool = st.form_submit_button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
    if not form_send:
        st.stop()

    start_feature_extraction_time = time.time()
    features: pd.DataFrame
    y: pd.DataFrame
    features, y = data_processing.feature_extraction(
        df=processed_data, chunksize=sidebar_settings.feature_extruction_chunksize, y_to_id_mapping=y_to_id_mapping
    )
    execution_feature_extraction_time: float = time.time() - start_feature_extraction_time
    st.write(f"–í—Ä–µ–º—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∏—á–µ–π: {execution_feature_extraction_time:.4f} —Å–µ–∫")

    features = features[main_features]

    with st.spinner("–ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ –º–æ–¥–µ–ª–∏"):
        y[f"{target_event_name}_occurrence_prob"] = model.predict_proba(features)[:, 1]

    y = transform_y(
        y_df=y,
        threadid_col_name=threadid_col_name,
        target_event_name=target_event_name,
        event_chain_id_col_le=event_chain_id_col_le,
    )
    st.download_button(
        label="–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
        data=prepare_for_excel_download(y),
        file_name=f"{result_file_name}.xlsx",
        icon=":material/download:",
    )


dataset_analyzing_page()
